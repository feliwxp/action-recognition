{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rckkXbS_QlwX"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import imageio\n",
        "from urllib.request import urlopen \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "50MUo7bjQm9C"
      },
      "outputs": [],
      "source": [
        "# get data labels\n",
        "data_labels = urlopen(\"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\n",
        ") \n",
        "labels = [line.decode(\"utf-8\").strip() for line in data_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "odnHHoRHQpE_"
      },
      "outputs": [],
      "source": [
        "# predict this video\n",
        "\n",
        "video_path = \"v_ApplyEyeMakeup_g01_c01.avi\"\n",
        "\n",
        "def crop_frame(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def get_frames(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_frame(frame)\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == 0:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames) / 255\n",
        "\n",
        "\n",
        "video_frames = get_frames(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzvfSx8XRoXf",
        "outputId": "d065e8f2-6ee9-48ea-c0b7-dc585e01b485"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(164, 224, 224, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video_frames.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rhY_4ZmmQqkT"
      },
      "outputs": [],
      "source": [
        "module = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\").signatures['default']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u02IqJK7SlZy"
      },
      "outputs": [],
      "source": [
        "def predict(module, video_frames):\n",
        "  video_frames = tf.cast(tf.convert_to_tensor(video_frames[None, :]), tf.float32)\n",
        "\n",
        "  logits = module(video_frames)['default'][0]\n",
        "  probabilities = tf.nn.softmax(logits)\n",
        "\n",
        "  print(\"Actions:\")\n",
        "  for i in np.argsort(probabilities)[::-1][:5]:\n",
        "    print(f\"  {labels[i]:22}: {probabilities[i] * 100:5.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf3a-h-pQsBP",
        "outputId": "f2432332-b9c5-4c27-e02c-a401c45d28f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions:\n",
            "  filling eyebrows      : 98.13%\n",
            "  applying cream        :  1.57%\n",
            "  waxing eyebrows       :  0.17%\n",
            "  playing harmonica     :  0.07%\n",
            "  brush painting        :  0.04%\n"
          ]
        }
      ],
      "source": [
        "predict(module, video_frames)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
